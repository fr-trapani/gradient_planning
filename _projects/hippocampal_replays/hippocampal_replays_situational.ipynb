{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from agents.pgp.pgp_softmax import SoftMaxPGP\n",
    "from environments.mutantworlds.mutantworlds_foster import FosterWorld\n",
    "from plots.gridworlds.gridworld_visualizer import GridWorldVisualizer\n",
    "from plots.gridworlds.gridworld_animator import GridWorldAnimator\n",
    "from utils.policy_tools import *\n",
    "from utils.policy_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maze Parameters\n",
    "maze = FosterWorld(goal_reward=100, doors_cost=-100, pillars_as_cost=False, small_version=False)\n",
    "\n",
    "# Agent Parameters\n",
    "gamma = 0.99\n",
    "p_situational = 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "replay_steps = 2000\n",
    "replay_alpha_kwargs = {'situational':0.95, 'alpha_norm':None, 'alpha_mean':0.2}\n",
    "replay_grad_kwargs={\"Î»\":0, \"natural\":False}\n",
    "replay_kld_threshold = 0.03\n",
    "\n",
    "# plot parameteres\n",
    "n_rows = 3\n",
    "n_cols = 3\n",
    "plot_n_histo_bins = 20\n",
    "animation_fps = 10\n",
    "animation_nframes = 50\n",
    "animation_id_prefix = \"__figures/hippocampal_replays/hippocampal_situational_#\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/fran-tr/Workspace/gpp_core/hippocampal_replays_situational.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fran-tr/Workspace/gpp_core/hippocampal_replays_situational.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mqt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fran-tr/Workspace/gpp_core/hippocampal_replays_situational.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mclose(\u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/fran-tr/Workspace/gpp_core/hippocampal_replays_situational.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mpause(\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fran-tr/Workspace/gpp_core/hippocampal_replays_situational.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m f_policies \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure(\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fran-tr/Workspace/gpp_core/hippocampal_replays_situational.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m f_divergences \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure(\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.11/site-packages/matplotlib/pyplot.py:584\u001b[0m, in \u001b[0;36mpause\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    582\u001b[0m     canvas\u001b[39m.\u001b[39mstart_event_loop(interval)\n\u001b[1;32m    583\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m     time\u001b[39m.\u001b[39msleep(interval)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "plt.close(\"all\")\n",
    "plt.pause(1)\n",
    "\n",
    "f_policies = plt.figure(1)\n",
    "f_divergences = plt.figure(2)\n",
    "\n",
    "for i_m in range(1, maze.n_mutations):\n",
    "    # change the configuration of the maze\n",
    "    maze.mutate(i_m)\n",
    "\n",
    "    # Reset the policy and the starting position\n",
    "    gpp = SoftMaxPGP(maze, gamma=gamma, p0_func=(lambda agent, s0s=None, p0s=None, situational=p_situational: p0_situational(agent, s0s, p0s, situational)))\n",
    "    viz = GridWorldVisualizer(maze, gpp)\n",
    "    ani = GridWorldAnimator(viz)\n",
    "\n",
    "    # Training\n",
    "    print(\"Foster's Maze #{}\".format(i_m+1))\n",
    "    gpp.learn(n_steps=replay_steps, alpha_func=situational_alpha, gradient_kwargs=replay_grad_kwargs, alpha_kwargs=replay_alpha_kwargs)\n",
    "    values, ranks, times, hist, mask, time_max = rank_states(gpp, f=policy_divergence, value_min=replay_kld_threshold, n_histo_bins=plot_n_histo_bins)\n",
    "\n",
    "    # Plot\n",
    "\n",
    "    plt.figure(f_policies.number)\n",
    "    plt.subplot(n_rows, n_cols, i_m)\n",
    "\n",
    "    viz.plot_trajectory_distribution(plot_maze=False, plot_axis=False, min_hue=0.1, max_hue=0.2)\n",
    "    viz.plot_maze(plot_grid=False, plot_axis=False, neg_rew_cmap=\"Greys\")\n",
    "    viz.plot_policy(plot_maze=False, plot_grid=False, plot_axis=False)\n",
    "    viz.plot_trajectory(plot_maze=False, plot_axis=False, greedy=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.pause(1)\n",
    "\n",
    "    plt.figure(f_divergences.number)\n",
    "    plt.subplot(n_rows, n_cols, i_m)\n",
    "\n",
    "    viz.plot_alpha_grid(hist, values, mask=mask, plot_axis=False, plot_grid=False, cmap=\"cool\")\n",
    "    viz.plot_maze(plot_grid=False, plot_axis=False, neg_rew_cmap=\"Greys\")\n",
    "    viz.plot_trajectory(greedy=True, plot_maze=False, plot_axis=False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.pause(1)\n",
    "\n",
    "    animation = ani.animate_gradient_colored(ts_interval=round(replay_steps/animation_nframes), fps=animation_fps)\n",
    "    animation_id = animation_id_prefix + str(i_m + 1) + \".mp4\"\n",
    "    animation.write_videofile(animation_id, fps=animation_fps)\n",
    "    plt.show()\n",
    "    plt.pause(1)\n",
    "\n",
    "plt.figure(f_policies.number)\n",
    "plt.savefig(animation_id_prefix + \"policies\" + \".png\")\n",
    "plt.figure(f_divergences.number)\n",
    "plt.savefig(animation_id_prefix + \"divergencies\" + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
