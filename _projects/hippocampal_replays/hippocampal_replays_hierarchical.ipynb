{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from agents.pgp.pgp_softmax import SoftMaxPGP\n",
    "from environments.mutantworlds.mutantworlds_foster import FosterFosterWorldMaze\n",
    "from plots.gridworlds.gridworld_visualizer import GridWorldVisualizer\n",
    "from plots.gridworlds.gridworld_animator import GridWorldAnimator\n",
    "from utils.policy_tools import *\n",
    "from utils.policy_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maze Parameters\n",
    "maze = FosterWorld(goal_reward=100, doors_cost=-100, pillars_as_cost=False, small_version=False)\n",
    "\n",
    "# Agent Parameters\n",
    "gamma = 0.99\n",
    "p_situational = 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "replay_steps = 2000\n",
    "replay_alpha_kwargs = {'situational':0.00, 'alpha_norm':None, 'alpha_mean':0.02}\n",
    "replay_grad_kwargs={\"Î»\":0, \"natural\":False}\n",
    "replay_kld_threshold = 0.03\n",
    "\n",
    "# plot parameteres\n",
    "n_rows = 3\n",
    "n_cols = 3\n",
    "plot_n_histo_bins = 20\n",
    "animation_fps = 10\n",
    "animation_nframes = 50\n",
    "animation_id_prefix = \"__figures/hippocampal_replays/hippocampal_hierarchical_#\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "plt.close(\"all\")\n",
    "plt.pause(1)\n",
    "\n",
    "f_policies = plt.figure(1)\n",
    "f_divergences = plt.figure(2)\n",
    "\n",
    "for i_m in range(1, maze.n_mutations):\n",
    "    # change the configuration of the maze\n",
    "    maze.mutate(i_m)\n",
    "\n",
    "    # Reset the policy and the starting position\n",
    "    gpp = SoftMaxPGP(maze, gamma=gamma, p0_func=(lambda agent, s0s=None, p0s=None, situational=p_situational: p0_situational(agent, s0s, p0s, situational)))\n",
    "    viz = GridWorldVisualizer(maze, gpp)\n",
    "    ani = GridWorldAnimator(viz)\n",
    "\n",
    "    # Training\n",
    "    print(\"Foster's Maze #{}\".format(i_m+1))\n",
    "    gpp.learn(n_steps=replay_steps, alpha_func=situational_alpha, gradient_kwargs=replay_grad_kwargs, alpha_kwargs=replay_alpha_kwargs)\n",
    "    values, ranks, times, hist, mask, time_max = rank_states(gpp, f=policy_divergence, value_min=replay_kld_threshold, n_histo_bins=plot_n_histo_bins)\n",
    "\n",
    "    # Plot\n",
    "\n",
    "    plt.figure(f_policies.number)\n",
    "    plt.subplot(n_rows, n_cols, i_m)\n",
    "\n",
    "    viz.plot_trajectory_distribution(plot_maze=False, plot_axis=False, min_hue=0.1, max_hue=0.2)\n",
    "    viz.plot_maze(plot_grid=False, plot_axis=False, neg_rew_cmap=\"Greys\")\n",
    "    viz.plot_policy(plot_maze=False, plot_grid=False, plot_axis=False)\n",
    "    viz.plot_trajectory(plot_maze=False, plot_axis=False, greedy=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.pause(1)\n",
    "\n",
    "    plt.figure(f_divergences.number)\n",
    "    plt.subplot(n_rows, n_cols, i_m)\n",
    "\n",
    "    viz.plot_alpha_grid(hist, values, mask=mask, plot_axis=False, plot_grid=False, cmap=\"cool\")\n",
    "    viz.plot_maze(plot_grid=False, plot_axis=False, neg_rew_cmap=\"Greys\")\n",
    "    viz.plot_trajectory(greedy=True, plot_maze=False, plot_axis=False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.pause(1)\n",
    "\n",
    "    animation = ani.animate_gradient_colored(ts_interval=round(replay_steps/animation_nframes), fps=animation_fps)\n",
    "    animation_id = animation_id_prefix + str(i_m + 1) + \".mp4\"\n",
    "    animation.write_videofile(animation_id, fps=animation_fps)\n",
    "    plt.show()\n",
    "    plt.pause(1)\n",
    "\n",
    "plt.figure(f_policies.number)\n",
    "plt.savefig(animation_id_prefix + \"policies\" + \".png\")\n",
    "plt.figure(f_divergences.number)\n",
    "plt.savefig(animation_id_prefix + \"divergencies\" + \".png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
